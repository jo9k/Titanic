{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools #iteration tools\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # nice plots\n",
    "import matplotlib.pyplot as plt # plots\n",
    "from ipy_table import *\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# machine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "both_df = [train_df, test_df]\n",
    "train_df.head()\n",
    "super_table=[]\n",
    "super_table.append(['name', 'reg_function', 'trainset_acc', 'testset_acc', 'r2score', 'conf_matrx'])\n",
    "df_load = pd.read_csv('table_eCh.csv')\n",
    "for row in df_load.values.tolist():\n",
    "    super_table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelling\n",
    "var_mod = ['Name', 'Sex', 'Ticket','Cabin', 'Embarked']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    mask = ~train_df[i].isnull()\n",
    "    train_df[i][mask] = le.fit_transform(train_df[i][mask])\n",
    "    mask2 = ~test_df[i].isnull()\n",
    "    test_df[i][mask2] = le.fit_transform(test_df[i][mask2])\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass Name Sex   Age  SibSp  Parch Ticket     Fare  \\\n",
       "0            1         0       3  108   1  22.0      1      0    523   7.2500   \n",
       "1            2         1       1  190   0  38.0      1      0    596  71.2833   \n",
       "2            3         1       3  353   0  26.0      0      0    669   7.9250   \n",
       "3            4         1       1  272   0  35.0      1      0     49  53.1000   \n",
       "4            5         0       3   15   1  35.0      0      0    472   8.0500   \n",
       "\n",
       "  Cabin Embarked  \n",
       "0   NaN        2  \n",
       "1    81        0  \n",
       "2   NaN        2  \n",
       "3    55        2  \n",
       "4   NaN        2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 9) (714, 10)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(['Cabin', 'Embarked'], axis=1)\n",
    "test_df = test_df.drop(['Cabin', 'Embarked'], axis=1)\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "train_df.head()\n",
    "print (test_df.shape, train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_regr_function(logreg, y_selection, x_selection):\n",
    "    coef = logreg.coef_[0]\n",
    "    intercept = \"{:.2f}\".format(logreg.intercept_[0])\n",
    "    output = y_selection + ' = ' + str(intercept) + ' + '\n",
    "    for coeff, feature in zip(coef, x_selection):\n",
    "        coeff_str = \"{:.2f}\".format(coeff)\n",
    "        output += coeff_str + \"*\" + feature + \" + \"\n",
    "    return output[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_date():\n",
    "    from time import gmtime, strftime\n",
    "    return strftime(\"%Y-%m-%d %H %M %S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2str(datalist):\n",
    "    return \" \".join([(str(var)+',') for var in datalist])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R2_score(logreg, X, y, sample_weight=None):\n",
    "    from sklearn.metrics import r2_score\n",
    "    return r2_score(y, logreg.predict(X), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(model, X, y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    return confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logist_reg_test (train_df, test_df, x_selection, submission_name = None, x_test_drop = \"PassengerId\"\n",
    "                     , y_selection = 'Survived'):\n",
    "    to_drop = [category for category in train_df.columns.values if category not in x_selection]\n",
    "    # learning set\n",
    "    X_train = train_df.drop(to_drop, axis=1)\n",
    "    # answers for learning set\n",
    "    Y_train = train_df[y_selection]\n",
    "    # testing set\n",
    "    to_drop.remove(y_selection)\n",
    "    to_drop.append(x_test_drop)\n",
    "    X_test  = test_df.drop(to_drop, axis=1).copy()\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    \n",
    "    #Calc parameters\n",
    "    function_str = get_regr_function(logreg, y_selection, x_selection)\n",
    "    trainset_acc = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "    r2_score = R2_score(logreg, X_train, Y_train)\n",
    "\n",
    "    conf_matrix = confusion_matrix(logreg,X_train,Y_train)\n",
    "    conf_matrix = 'TN: '+str(conf_matrix[0][0])+', FP: '+str(conf_matrix[0][1])+ \\\n",
    "                      ', FN: '+str(conf_matrix[1][0])+', TP: '+str(conf_matrix[1][1])\n",
    "    #prints\n",
    "    print('Regression function:\\n', function_str)\n",
    "    print('Accuracy on train set:', trainset_acc)\n",
    "    print(\"R2 score:\", r2_score)\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    \n",
    "    #make predictions\n",
    "    Y_pred = logreg.predict(X_test)\n",
    "    #export predictions\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[x_test_drop],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "    if submission_name == None:\n",
    "        submission_name = \"regression\"+write_date()\n",
    "    submission.to_csv(r'C:/Users/ernest.chocholowski/Desktop/Datasets/Titanic/output/'+submission_name+'.csv', index=False)\n",
    "    \n",
    "    return [submission_name, function_str, str(trainset_acc), r2_score, conf_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_drop = \"PassengerId\"\n",
    "y_selection = 'Survived'\n",
    "x_selection = train_df.columns.values\n",
    "x_selection = np.delete(x_selection, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression function:\n",
      " Survived = 3.99 + -0.85*Pclass + -0.00*Name + -2.35*Sex + -0.03*Age + -0.32*SibSp + -0.06*Parch + -0.00*Ticket + 0.01*Fare\n",
      "Accuracy on train set: 79.97\n",
      "R2 score: 0.169632400781\n",
      "Confusion matrix:\n",
      " TN: 369, FP: 55, FN: 88, TP: 202\n"
     ]
    }
   ],
   "source": [
    "output = logist_reg_test(train_df, test_df, x_selection, submission_name='logisticReg_basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset_acc = str('failed_evl')\n",
    "output.insert(3, testset_acc)\n",
    "super_table.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_regr_fun_lin(logreg, y_selection, x_selection):\n",
    "    coef = logreg.coef_\n",
    "    intercept = \"{:.2f}\".format(logreg.intercept_)\n",
    "    output = y_selection + ' = ' + str(intercept) + ' + '\n",
    "    for coeff, feature in zip(coef, x_selection):\n",
    "        coeff_str = \"{:.2f}\".format(coeff)\n",
    "        output += coeff_str + \"*\" + feature + \" + \"\n",
    "    return output[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_reg_test (train_df, test_df, x_selection, submission_name = None, x_test_drop = \"PassengerId\"\n",
    "                     , y_selection = 'Survived'):\n",
    "    to_drop = [category for category in train_df.columns.values if category not in x_selection]\n",
    "    # learning set\n",
    "    X_train = train_df.drop(to_drop, axis=1)\n",
    "    # answers for learning set\n",
    "    Y_train = train_df[y_selection]\n",
    "    # testing set\n",
    "    to_drop.remove(y_selection)\n",
    "    to_drop.append(x_test_drop)\n",
    "    X_test  = test_df.drop(to_drop, axis=1).copy()\n",
    "    # Logistic Regression\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, Y_train)\n",
    "    #Calc parameters\n",
    "    function_str = get_regr_fun_lin(linreg, y_selection, x_selection)\n",
    "    trainset_acc = round(linreg.score(X_train, Y_train) * 100, 2)\n",
    "    r2_score = R2_score(linreg, X_train, Y_train)\n",
    "\n",
    "    conf_matrix = \"NA\"\n",
    "    \n",
    "    #prints\n",
    "    print('Regression function:\\n', function_str)\n",
    "    print('Accuracy on train set:', trainset_acc)\n",
    "    print(\"R2 score:\", r2_score)\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    \n",
    "    #make predictions\n",
    "    Y_pred = linreg.predict(X_test)\n",
    "    #export predictions\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[x_test_drop],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "    if submission_name == None:\n",
    "        submission_name = \"regression\"+write_date()\n",
    "    submission.to_csv(r'C:/Users/ernest.chocholowski/Desktop/Datasets/Titanic/output/'+submission_name+'.csv', \n",
    "                      index=False)\n",
    "    \n",
    "    return [submission_name, function_str, str(trainset_acc), r2_score, conf_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_drop = \"PassengerId\"\n",
    "y_selection = 'Survived'\n",
    "x_selection = train_df.columns.values\n",
    "x_selection = np.delete(x_selection, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression function:\n",
      " Survived = 1.40 + -0.19*Pclass + -0.00*Name + -0.49*Sex + -0.01*Age + -0.06*SibSp + -0.01*Parch + -0.00*Ticket + 0.00*Fare\n",
      "Accuracy on train set: 40.25\n",
      "R2 score: 0.402525234523\n",
      "Confusion matrix:\n",
      " NA\n"
     ]
    }
   ],
   "source": [
    "output = linear_reg_test(train_df, test_df, x_selection, submission_name='linearReg_basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset_acc = str('failed_evl')\n",
    "output.insert(3, testset_acc)\n",
    "super_table.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def other_tests (model, train_df, test_df, x_selection, submission_name = None, x_test_drop = \"PassengerId\"\n",
    "                     , y_selection = 'Survived'):\n",
    "    to_drop = [category for category in train_df.columns.values if category not in x_selection]\n",
    "    # learning set\n",
    "    X_train = train_df.drop(to_drop, axis=1)\n",
    "    # answers for learning set\n",
    "    Y_train = train_df[y_selection]\n",
    "    # testing set\n",
    "    to_drop.remove(y_selection)\n",
    "    to_drop.append(x_test_drop)\n",
    "    X_test  = test_df.drop(to_drop, axis=1).copy()\n",
    "    # Logistic Regression\n",
    "    model.fit(X_train, Y_train)\n",
    "    #Calc parameters\n",
    "    trainset_acc = round(model.score(X_train, Y_train) * 100, 2)\n",
    "    r2_score = R2_score(model, X_train, Y_train)\n",
    "    function_str = 'NA'\n",
    "    conf_matrix = confusion_matrix(model, X_train, Y_train)\n",
    "    conf_matrix = 'TN: '+str(conf_matrix[0][0])+', FP: '+str(conf_matrix[0][1])+ \\\n",
    "                      ', FN: '+str(conf_matrix[1][0])+', TP: '+str(conf_matrix[1][1])\n",
    "    \n",
    "    #prints\n",
    "    print('Regression function:\\n', function_str)\n",
    "    print('Accuracy on train set:', trainset_acc)\n",
    "    print(\"R2 score:\", r2_score)\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    \n",
    "    #make predictions\n",
    "    Y_pred = model.predict(X_test)\n",
    "    #export predictions\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[x_test_drop],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "    if submission_name == None:\n",
    "        submission_name = \"regression\"+write_date()\n",
    "    submission.to_csv(r'C:/Users/ernest.chocholowski/Desktop/Datasets/Titanic/output/'+submission_name+'.csv', \n",
    "                      index=False)\n",
    "    \n",
    "    return [submission_name, function_str, str(trainset_acc), r2_score, conf_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_drop = \"PassengerId\"\n",
    "y_selection = 'Survived'\n",
    "x_selection = train_df.columns.values\n",
    "x_selection = np.delete(x_selection, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression function:\n",
      " NA\n",
      "Accuracy on train set: 100.0\n",
      "R2 score: 1.0\n",
      "Confusion matrix:\n",
      " TN: 424, FP: 0, FN: 0, TP: 290\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "output = other_tests(model, train_df, test_df, x_selection, submission_name='RandomForestClassifier_basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset_acc = str('failed_evl')\n",
    "output.insert(3, testset_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "6 columns passed, passed data had 7 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-847-469de11cac0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msuper_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msuper_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuper_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuper_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m df.to_csv(r'C:/Users/ernest.chocholowski/Desktop/GIT/Titanic/table_eCh.csv', \n\u001b[0;32m      7\u001b[0m                       index=False)\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5713\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5714\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m-> 5715\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m   5716\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5717\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5792\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5793\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m-> 5794\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ernest.chocholowski\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5851\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5852\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[1;32m-> 5853\u001b[1;33m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[0;32m   5854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5855\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 6 columns passed, passed data had 7 columns"
     ]
    }
   ],
   "source": [
    "super_table.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" cellpadding=\"3\" cellspacing=\"0\"  style=\"border:1px solid black;border-collapse:collapse;\"><tr><td  style=\"background-color:LightGray;\"><b>name</b></td><td  style=\"background-color:LightGray;\"><b>reg_function</b></td><td  style=\"background-color:LightGray;\"><b>trainset_acc</b></td><td  style=\"background-color:LightGray;\"><b>testset_acc</b></td><td  style=\"background-color:LightGray;\"><b>r2score</b></td><td  style=\"background-color:LightGray;\"><b>conf_matrx</b></td></tr><tr><td  style=\"background-color:Ivory;\">logisticReg_basic</td><td  style=\"background-color:Ivory;\">Survived&nbsp=&nbsp3.99&nbsp+&nbsp-0.85*Pclass&nbsp+&nbsp-0.00*Name&nbsp+&nbsp-2.35*Sex&nbsp+&nbsp-0.03*Age&nbsp+&nbsp-0.32*SibSp&nbsp+&nbsp-0.06*Parch&nbsp+&nbsp-0.00*Ticket&nbsp+&nbsp0.01*Fare</td><td  style=\"background-color:Ivory;\">79.97</td><td  style=\"background-color:Ivory;\">failed_evl</td><td  style=\"background-color:Ivory;\">0.1696324007807416</td><td  style=\"background-color:Ivory;\">TN:&nbsp369,&nbspFP:&nbsp55,&nbspFN:&nbsp88,&nbspTP:&nbsp202</td></tr><tr><td  style=\"background-color:AliceBlue;\">linearReg_basic</td><td  style=\"background-color:AliceBlue;\">Survived&nbsp=&nbsp1.40&nbsp+&nbsp-0.19*Pclass&nbsp+&nbsp-0.00*Name&nbsp+&nbsp-0.49*Sex&nbsp+&nbsp-0.01*Age&nbsp+&nbsp-0.06*SibSp&nbsp+&nbsp-0.01*Parch&nbsp+&nbsp-0.00*Ticket&nbsp+&nbsp0.00*Fare</td><td  style=\"background-color:AliceBlue;\">40.25</td><td  style=\"background-color:AliceBlue;\">failed_evl</td><td  style=\"background-color:AliceBlue;\">0.4025252345231439</td><td  style=\"background-color:AliceBlue;\">nan</td></tr><tr><td  style=\"background-color:Ivory;\">SVC_basic</td><td  style=\"background-color:Ivory;\">nan</td><td  style=\"background-color:Ivory;\">99.86</td><td  style=\"background-color:Ivory;\">failed_evl</td><td  style=\"background-color:Ivory;\">0.9941932335718932</td><td  style=\"background-color:Ivory;\">TN:&nbsp424,&nbspFP:&nbsp0,&nbspFN:&nbsp1,&nbspTP:&nbsp289</td></tr><tr><td  style=\"background-color:AliceBlue;\">KNC_basic</td><td  style=\"background-color:AliceBlue;\">nan</td><td  style=\"background-color:AliceBlue;\">82.49</td><td  style=\"background-color:AliceBlue;\">failed_evl</td><td  style=\"background-color:AliceBlue;\">0.2741541964866623</td><td  style=\"background-color:AliceBlue;\">TN:&nbsp356,&nbspFP:&nbsp68,&nbspFN:&nbsp57,&nbspTP:&nbsp233</td></tr><tr><td  style=\"background-color:Ivory;\">GaussianNB_basic</td><td  style=\"background-color:Ivory;\">nan</td><td  style=\"background-color:Ivory;\">78.57</td><td  style=\"background-color:Ivory;\">failed_evl</td><td  style=\"background-color:Ivory;\">0.11156473649967458</td><td  style=\"background-color:Ivory;\">TN:&nbsp352,&nbspFP:&nbsp72,&nbspFN:&nbsp81,&nbspTP:&nbsp209</td></tr><tr><td  style=\"background-color:AliceBlue;\">Perceptron_basic</td><td  style=\"background-color:AliceBlue;\">nan</td><td  style=\"background-color:AliceBlue;\">62.46</td><td  style=\"background-color:AliceBlue;\">failed_evl</td><td  style=\"background-color:AliceBlue;\">-0.5562134027325961</td><td  style=\"background-color:AliceBlue;\">TN:&nbsp417,&nbspFP:&nbsp7,&nbspFN:&nbsp261,&nbspTP:&nbsp29</td></tr><tr><td  style=\"background-color:Ivory;\">LinearSVC_basic</td><td  style=\"background-color:Ivory;\">nan</td><td  style=\"background-color:Ivory;\">49.44</td><td  style=\"background-color:Ivory;\">failed_evl</td><td  style=\"background-color:Ivory;\">-1.0962426805465193</td><td  style=\"background-color:Ivory;\">TN:&nbsp94,&nbspFP:&nbsp330,&nbspFN:&nbsp31,&nbspTP:&nbsp259</td></tr><tr><td  style=\"background-color:AliceBlue;\">SGDClassifier_basic</td><td  style=\"background-color:AliceBlue;\">nan</td><td  style=\"background-color:AliceBlue;\">65.69</td><td  style=\"background-color:AliceBlue;\">failed_evl</td><td  style=\"background-color:AliceBlue;\">-0.42265777488614203</td><td  style=\"background-color:AliceBlue;\">TN:&nbsp330,&nbspFP:&nbsp94,&nbspFN:&nbsp151,&nbspTP:&nbsp139</td></tr><tr><td  style=\"background-color:Ivory;\">DecisionTreeClassifier_basic</td><td  style=\"background-color:Ivory;\">nan</td><td  style=\"background-color:Ivory;\">100.0</td><td  style=\"background-color:Ivory;\">failed_evl</td><td  style=\"background-color:Ivory;\">1.0</td><td  style=\"background-color:Ivory;\">TN:&nbsp424,&nbspFP:&nbsp0,&nbspFN:&nbsp0,&nbspTP:&nbsp290</td></tr><tr><td  style=\"background-color:AliceBlue;\">RandomForestClassifier_basic</td><td  style=\"background-color:AliceBlue;\">nan</td><td  style=\"background-color:AliceBlue;\">100.0</td><td  style=\"background-color:AliceBlue;\">failed_evl</td><td  style=\"background-color:AliceBlue;\">1.0</td><td  style=\"background-color:AliceBlue;\">TN:&nbsp424,&nbspFP:&nbsp0,&nbspFN:&nbsp0,&nbspTP:&nbsp290</td></tr></table>"
      ],
      "text/plain": [
       "<ipy_table.IpyTable at 0x1f8dc84c9e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_table(super_table)\n",
    "apply_theme('basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(super_table[1:], columns=super_table[0])\n",
    "df.to_csv(r'C:/Users/ernest.chocholowski/Desktop/GIT/Titanic/table_eCh.csv', \n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
